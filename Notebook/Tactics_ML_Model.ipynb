{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "11d47514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, fbeta_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "from plotly.subplots import make_subplots\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn.metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c08ed5",
   "metadata": {},
   "source": [
    "# Opening Files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "12b98ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcatt_data = '../src/rcatt_training_data_original.csv'\n",
    "scraped_data = '../src/training_dataset_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dfcaaa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform into dataframes: \n",
    "\n",
    "df_r = pd.read_csv(rcatt_data).reset_index(drop = True)\n",
    "df_r = df_r[~df_r['Text'].duplicated()]\n",
    "df_s = pd.read_csv(scraped_data).reset_index(drop = True).rename(columns={'text': 'Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bea6fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from string to list using literal_eval:\n",
    "\n",
    "for col in ['mitre_domain', 'tech_name', 'tech_id', 'tactic_id', 'software_id']:\n",
    "    df_s[col] = df_s[col].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e779f",
   "metadata": {},
   "source": [
    "# Merging Files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9778d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_s = mlb.fit_transform(df_s['tactic_id'])\n",
    "Y_s = pd.DataFrame(Y_s, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8062a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = df_r['Text']\n",
    "Y_r = df_r[[col for col in df_r.columns if col.startswith('TA')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "77b851a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Y_s[Y_r.columns]\n",
    "Y_s = Y1[Y1.sum(axis=1)>0] \n",
    "X_s = df_s['Text']\n",
    "X_s = X_s[Y1.sum(axis=1)>0] # all urls who map at least one of the techniques in Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8dde9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r_train, X_test_text, Y_r_train, Y_test = train_test_split(X_r, Y_r, test_size=0.3,\n",
    "                                                    random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c2208d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = pd.concat([X_r_train, X_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a0630401",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.concat([Y_r_train, Y_s]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f1e85fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liviafries/opt/anaconda3/envs/auto_cti/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/liviafries/opt/anaconda3/envs/auto_cti/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ------------ Count Vectorizer --------------- \n",
    "\n",
    "# cv = CountVectorizer(analyzer='word', stop_words='english', lowercase=False,\n",
    "                        #min_df=0.01) # if words used less than 0.001 % --> ignore  \n",
    "# data = cv.fit_transform(df_tech['text']) \n",
    "\n",
    "# df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "# ---------------- TF-IDF ---------------------: \n",
    "\n",
    "\n",
    "tf_idf = TfidfVectorizer(analyzer = 'word', stop_words='english', lowercase=True, min_df=2, max_df=0.99)\n",
    "\n",
    "X_train = tf_idf.fit_transform(X_train_text)\n",
    "\n",
    "X_train = pd.DataFrame(X_train.toarray(), columns=tf_idf.get_feature_names()) \n",
    "\n",
    "X_test = tf_idf.transform(X_test_text)\n",
    "\n",
    "X_test = pd.DataFrame(X_test.toarray(), columns=tf_idf.get_feature_names()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e9aeb",
   "metadata": {},
   "source": [
    "# Measuring Cosine Similarity to Remove Duplicates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "338ce0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2bd8dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = set()\n",
    "for i in range(similarities.shape[0]):\n",
    "    for j in range(similarities.shape[1]):\n",
    "        if similarities[i][j] > 0.9:\n",
    "            # print(i, j, similarities[i][j])\n",
    "            duplicates.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "83a4f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[~X_train.index.isin(duplicates)]\n",
    "Y_train = Y_train[~Y_train.index.isin(duplicates)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985276b",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a4503",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "90b998f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(class_weight='balanced', dual=False,\n",
       "                                        random_state=42),\n",
       "                    n_jobs=1)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test: First delete techniques less than 9 \n",
    "# We fix the random state to have the same dataset in our different tests\n",
    "\n",
    "sv_classifier = OneVsRestClassifier(LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, max_iter = 1000, class_weight = 'balanced', random_state=42), n_jobs = 1)\n",
    "sv_classifier.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c0a294f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(sv_classifier.predict(X_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cbba160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA0006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       352\n",
      "           1       0.67      0.65      0.66        89\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.79      0.79      0.79       441\n",
      "weighted avg       0.86      0.87      0.87       441\n",
      "\n",
      "TA0002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       308\n",
      "           1       0.72      0.68      0.70       133\n",
      "\n",
      "    accuracy                           0.82       441\n",
      "   macro avg       0.79      0.78      0.79       441\n",
      "weighted avg       0.82      0.82      0.82       441\n",
      "\n",
      "TA0040\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       421\n",
      "           1       0.59      0.65      0.62        20\n",
      "\n",
      "    accuracy                           0.96       441\n",
      "   macro avg       0.79      0.81      0.80       441\n",
      "weighted avg       0.97      0.96      0.96       441\n",
      "\n",
      "TA0003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84       262\n",
      "           1       0.79      0.68      0.73       179\n",
      "\n",
      "    accuracy                           0.80       441\n",
      "   macro avg       0.79      0.78      0.78       441\n",
      "weighted avg       0.80      0.80      0.79       441\n",
      "\n",
      "TA0004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       320\n",
      "           1       0.61      0.57      0.59       121\n",
      "\n",
      "    accuracy                           0.78       441\n",
      "   macro avg       0.72      0.71      0.72       441\n",
      "weighted avg       0.78      0.78      0.78       441\n",
      "\n",
      "TA0008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       338\n",
      "           1       0.62      0.58      0.60       103\n",
      "\n",
      "    accuracy                           0.82       441\n",
      "   macro avg       0.75      0.74      0.74       441\n",
      "weighted avg       0.82      0.82      0.82       441\n",
      "\n",
      "TA0005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       227\n",
      "           1       0.81      0.74      0.77       214\n",
      "\n",
      "    accuracy                           0.79       441\n",
      "   macro avg       0.79      0.79      0.79       441\n",
      "weighted avg       0.79      0.79      0.79       441\n",
      "\n",
      "TA0010\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       411\n",
      "           1       0.44      0.47      0.45        30\n",
      "\n",
      "    accuracy                           0.92       441\n",
      "   macro avg       0.70      0.71      0.71       441\n",
      "weighted avg       0.93      0.92      0.92       441\n",
      "\n",
      "TA0007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       340\n",
      "           1       0.80      0.68      0.74       101\n",
      "\n",
      "    accuracy                           0.89       441\n",
      "   macro avg       0.86      0.82      0.83       441\n",
      "weighted avg       0.89      0.89      0.89       441\n",
      "\n",
      "TA0009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       376\n",
      "           1       0.65      0.68      0.66        65\n",
      "\n",
      "    accuracy                           0.90       441\n",
      "   macro avg       0.80      0.81      0.80       441\n",
      "weighted avg       0.90      0.90      0.90       441\n",
      "\n",
      "TA0011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       336\n",
      "           1       0.72      0.80      0.76       105\n",
      "\n",
      "    accuracy                           0.88       441\n",
      "   macro avg       0.83      0.85      0.84       441\n",
      "weighted avg       0.88      0.88      0.88       441\n",
      "\n",
      "TA0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       378\n",
      "           1       0.59      0.51      0.55        63\n",
      "\n",
      "    accuracy                           0.88       441\n",
      "   macro avg       0.76      0.72      0.74       441\n",
      "weighted avg       0.87      0.88      0.88       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_score_dict = {}\n",
    "for col in Y_test.columns:\n",
    "    print(col)\n",
    "    f_score_dict[col] = fbeta_score(Y_test[col], Y_pred[col],beta=0.5)\n",
    "    print(classification_report(Y_test[col], Y_pred[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cd5fcf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TA0006': 0.6697459584295612,\n",
       " 'TA0002': 0.7109004739336492,\n",
       " 'TA0040': 0.6018518518518519,\n",
       " 'TA0003': 0.7634543178973716,\n",
       " 'TA0004': 0.5979202772963604,\n",
       " 'TA0008': 0.6109979633401221,\n",
       " 'TA0005': 0.7934131736526946,\n",
       " 'TA0010': 0.4430379746835443,\n",
       " 'TA0007': 0.7752808988764045,\n",
       " 'TA0009': 0.6528189910979229,\n",
       " 'TA0011': 0.7329842931937174,\n",
       " 'TA0001': 0.5734767025089605}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3245349f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6604902397301801"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(f_score_dict.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
