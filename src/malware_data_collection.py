from ast import keyword
from operator import le
import os
import json, time
from sys import base_exec_prefix
from bs4 import BeautifulSoup
import requests
from collections import defaultdict
import traceback
from scipy import random # generates default key if missing 

def GatherData(links):
    link = 0
    while link<len(links):
        remain =len(links)- link+1
        print('Loading:{} & Remaining:{}'.format(link+1,remain-1))
        try:
            print('Requesting:{}'.format(links[link]))
            response = requests.get(links[link], timeout = 20)
            if response.status_code == 200:
                Soup = BeautifulSoup(response.content,'html5lib')
                main_page_id = Soup.find('div',{'id':'card-id'}).text.split('ID:')[1].strip().split(' ')[0]
                header= Soup.find('h2',{'id':'references'}).find_next_sibling('div')
                refrences = []
                for r in header.find_all('ol'):
                    for l in r.find_all('li'):
                        refrences.append(l.find('a').get('href'))
                    pass
                pass
                MainTable = Soup.find('table',{'class':'techniques-used'})
                for data in MainTable.find('tbody').find_all('tr'):
                    
                    print('Domain:{}'.format(data.find_all('td')[0].text.strip()))
                    print('Technique ID:{}'.format(data.find_all('td')[1].text.strip()))
                    if data.find_all('td')[0].text.strip():
                        domain = data.find_all('td')[0].text.strip()
                    
                    print('Technique Name: {}'.format(data.find_all('td')[-2].text.strip()))
                    tech_name = data.find_all('td')[-2].text.strip()
                    
                    if data.find_all('td')[1].text.strip():
                        tech_id = data.find_all('td')[1].text.strip()
                    software_id = main_page_id
                    for re in data.find_all('td')[-1].find_all('a'):
                        url = re.get('href')
                    
                        if not url.startswith('/') and 'attack.mitre' not in url:
                            if domain not in dataset[url]['mitre_domain']:
                                dataset[url]['mitre_domain'].append(domain)
                            if tech_name not in dataset[url]['tech_name']:
                                dataset[url]['tech_name'].append(tech_name)
                            if tech_id not in dataset[url]['tech_id']:
                                dataset[url]['tech_id'].append(tech_id)
                            if software_id not in dataset[url]['software_id']:
                                dataset[url]['software_id'].append(software_id)
                        print('Ref Link:{} & Ref Number:{}'.format(re.get('href'),re.text))
                    pass
                pass
                #main_dictionary[' '] = dict(external_ref_list)
                 # wait until finish end before dumping ! 
                with open('training_malware.json','w', encoding='utf-8') as outfile:
                    json.dump(dataset, outfile,indent=4)
                print('\t\t\t  Data Save Successfully  ')
                
                #data[0].items()
        except KeyboardInterrupt:
            raise
        except BaseException as E:
            print(traceback.format_exc())
        pass
        link+=1
        #time.sleep(random.randint(5,8))
    pass

if __name__ == '__main__':
    
    external_ref_list = []
    dataset = defaultdict(lambda: defaultdict(list))
    # loop through enterprise attack-pattern:
    root_folder = '../data/'
    folder_names = ['ics-malware', 'malware']
    for folder_name in folder_names: 
        folder = os.path.join(root_folder, folder_name)
        for filename in os.listdir(folder): 
            if filename.endswith('.json'):
                with open(os.path.join(folder, filename)) as file:
                    file_json = json.load(file)["objects"][0]
                    # retrieve information:
                    if 'x_mitre_aliases' in file_json:
                        attack_names = file_json['x_mitre_aliases']
                    else:
                        attack_names = [file_json['name']]
                    pass
                    urls = []  
                    for ref in file_json['external_references']:
                        for key, value in ref.items():
                            if key.__contains__('url'):
                                if value.__contains__('https://attack.mitre.org/'):
                                    #print(value)
                                    urls.append(value)
                                pass
                        pass
                    pass
                    if len(urls) > 0:
                        GatherData(urls)
                pass
            pass
        pass
    pass
        
